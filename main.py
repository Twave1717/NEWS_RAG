import streamlit as st
from streamlit_chat import message  # streamlit-chat ì‚¬ìš©
import time
import os
from datetime import datetime, timedelta

import requests  # API ìš”ì²­ì„ ìœ„í•´ ì¶”ê°€

from dotenv import load_dotenv
load_dotenv()  # .env íŒŒì¼ ë¡œë“œ

# langchain-teddynote
from langchain_teddynote import logging
logging.langsmith("CH12-RAG")

from langchain import hub
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

from langchain.schema import Document


##################################################
# (0) ë§¤ì¼ 00:01(=12ì‹œ1ë¶„)ì— ìºì‹œë¥¼ ê°±ì‹ í•˜ê¸° ìœ„í•œ ë¡œì§
##################################################
def refresh_cache_if_1201():
    """
    ë§¤ì¼ 00:01(=12ì‹œ1ë¶„)ì´ ë˜ë©´ ìºì‹œë¥¼ ì´ˆê¸°í™”í•˜ì—¬
    ë‹¤ìŒ í˜¸ì¶œ ì‹œ ìƒˆë¡œ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§(=APIë¡œ ê°€ì ¸ì˜¤ê¸°)í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    """
    now = datetime.now()
    # ì‹œ/ë¶„ì´ ê°ê° 0,1 ì´ë©´ cache clear
    if (now.hour == 0 and now.minute == 1):
        st.cache_resource.clear()
        st.experimental_rerun()


##################################################
# (1) DeepSearch APIë¡œ ë‰´ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° (Selenium ì œê±°)
##################################################
def fetch_news_api():
    """
    ì „ë‚ ë¶€í„° 1ì£¼ì¼ì¹˜(ì¦‰, ì–´ì œ ë‚ ì§œ ~ 7ì¼ ì „ ë‚ ì§œ) ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼
    DeepSearch APIë¡œ ëª¨ë‘ ë¶ˆëŸ¬ì™€ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    ë°˜í™˜ í˜•ì‹:
    [
      {
        "id": ...,
        "title": ...,
        "title_ko": ...,
        "summary": ...,
        "summary_ko": ...,
        "content_url": ...,
        "published_at": ...,
        ...
      },
      ...
    ]
    """
    # ë‚ ì§œ ì„¤ì • (ì–´ì œ ~ 7ì¼ ì „)
    end_date_dt = datetime.now() - timedelta(days=1)
    start_date_dt = datetime.now() - timedelta(days=7)
    date_from_str = start_date_dt.strftime("%Y-%m-%d")
    date_to_str = end_date_dt.strftime("%Y-%m-%d")

    # .env íŒŒì¼ì—ì„œ API_KEY ë¶ˆëŸ¬ì˜¤ê¸°
    API_KEY = "5d1ca2322d974c129b89b2937f736bfa"
    if not API_KEY:
        st.error("DEEPSEARCH_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []

    BASE_URL = "https://api-v2.deepsearch.com/v1/global-articles/economy"
    page_size = 100

    # articles ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    all_articles = []

    # ìš°ì„  1í˜ì´ì§€ë¥¼ í˜¸ì¶œí•˜ì—¬ total_pages í™•ì¸
    page = 1
    url = (
        f"{BASE_URL}?api_key={API_KEY}"
        f"&date_from={date_from_str}&date_to={date_to_str}"
        f"&page={page}&page_size={page_size}"
    )
    resp = requests.get(url)
    if resp.status_code != 200:
        st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {resp.status_code}")
        return []

    data_json = resp.json()
    total_pages = data_json.get("total_pages", 1)
    items = data_json.get("data", [])
    all_articles.extend(items)

    # 2í˜ì´ì§€ ~ total_pagesê¹Œì§€ ë°˜ë³µ
    for page_num in range(2, total_pages + 1):
        url = (
            f"{BASE_URL}?api_key={API_KEY}"
            f"&date_from={date_from_str}&date_to={date_to_str}"
            f"&page={page_num}&page_size={page_size}"
        )
        resp = requests.get(url)
        if resp.status_code == 200:
            data_json = resp.json()
            items = data_json.get("data", [])
            all_articles.extend(items)
        else:
            st.warning(f"í˜ì´ì§€ {page_num} í˜¸ì¶œ ì‹¤íŒ¨: {resp.status_code}")
            break

    return all_articles


##################################################
# (2) RAG (ì¸ë±ì‹±ì— ì‚¬ìš©)
##################################################
def create_retriever_from_articles(articles):
    """
    ê°€ì ¸ì˜¨ articlesë¥¼ ë°”íƒ•ìœ¼ë¡œ 2ê°€ì§€ ë¬¸ì„œë¥¼ ë§Œë“  ë’¤,
    - (ë¬¸ì„œ1) ëª¨ë“  ê¸°ì‚¬ë‚´ìš©(ì˜ë¬¸/í•œê¸€ìš”ì•½/ë³¸ë¬¸url ë“±)ì„ í•©ì³ì„œ í•˜ë‚˜ì˜ í° í…ìŠ¤íŠ¸ë¡œ
    - (ë¬¸ì„œ2) "YYYYë…„ MMì›” DDì¼ ì¦ì‹œ ìš”ì•½" + ê¸°ì‚¬ì œëª©ë“¤ë§Œ ëª¨ì•„ ë†“ì€ í…ìŠ¤íŠ¸

    ë‘ ë¬¸ì„œë¥¼ í•©ì³ì„œ í•˜ë‚˜ì˜ retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # (A) ëª¨ë“  ê¸°ì‚¬ ë‚´ìš©ì„ í•©ì¹˜ëŠ” ë¬¸ì„œ
    all_text_list = []
    for art in articles:
        title = art.get("title", "")
        title_ko = art.get("title_ko", "")
        summary = art.get("summary", "")
        summary_ko = art.get("summary_ko", "")
        pub_at = art.get("published_at", "")
        content_url = art.get("content_url", "")
        reason = art.get("reason", "")

        one_text = (
            f"[ê¸°ì‚¬ID: {art.get('id')}]\n\n"
            f"ì˜ë¬¸ì œëª©: {title}\n"
            # f"í•œê¸€ì œëª©: {title_ko}\n"  # í•œê¸€ ì œëª© ì œì™¸
            f"ë°œí–‰ì¼: {pub_at}\n"
            # f"ë‚´ìš©URL: {content_url}\n"  # ë‚´ìš© URL ì œì™¸
            f"ì˜ë¬¸ìš”ì•½: {summary}\n"
            # f"í•œê¸€ìš”ì•½: {summary_ko}\n"  # í•œê¸€ ìš”ì•½ ì œì™¸
            f"reason: {reason}\n\n"
            "----------------------------"
        )

        all_text_list.append(one_text)

    doc_text_1 = "\n".join(all_text_list)

    # (B) "YYYYë…„ MMì›” DDì¼ ì¦ì‹œ ìš”ì•½" í˜•íƒœë¡œ ê¸°ì‚¬ì œëª©ë“¤ë§Œ ëª¨ì€ ë¬¸ì„œ
    today_str = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    header = f"{today_str} ì¦ì‹œ ìš”ì•½\n\n"
    titles_only_list = []
    for art in articles:
        t_ko = art.get("title_ko", "")
        t_en = art.get("title", "")
        if t_ko:
            titles_only_list.append(f"- {t_ko}")
        else:
            titles_only_list.append(f"- {t_en}")

    doc_text_2 = header + "\n".join(titles_only_list) + "\n"

    # (C) ë‘ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ
    docs = [
        Document(page_content=doc_text_1),
        Document(page_content=doc_text_2),
    ]

    # (D) í…ìŠ¤íŠ¸ ë¶„í•  & ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    splits = text_splitter.split_documents(docs)

    vectorstore = FAISS.from_documents(splits, OpenAIEmbeddings())
    retriever = vectorstore.as_retriever()
    return retriever


prompt = PromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ì§€ê¸ˆê¹Œì§€ì˜ (ìµœê·¼) ëŒ€í™” ë‚´ìš© ì¼ë¶€ì…ë‹ˆë‹¤:
{chat_history}

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”, ì£¼ì–´ì§„ ë‰´ìŠ¤ ë¬¸ë§¥(context)ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸(question)ì— ë‹µë³€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

# Question:
{question}

# Context:
{context}

# Answer:"""
)

llm = ChatOpenAI(model_name="gpt-4", temperature=0)  # ëª¨ë¸ ì´ë¦„ ìˆ˜ì •
rag_chain = (
    {
        "context": RunnablePassthrough(),
        "question": RunnablePassthrough(),
        "chat_history": RunnablePassthrough()
    }
    | prompt
    | llm
    | StrOutputParser()
)


##################################################
# (2-1) ë§¤ë²ˆ ìƒˆë¡œ ì•ˆ í•˜ê³ , "ê³µìœ  ë°ì´í„°"ë¥¼ ìºì‹œì— ì €ì¥
##################################################
@st.cache_resource
def get_cached_articles_and_retriever():
    """
    - ì„œë²„ê°€ ì‹¤í–‰ëœ í›„ ìµœì´ˆ 1íšŒ, ê·¸ë¦¬ê³  cacheê°€ ë¹„ì›Œì¡Œì„ ë•Œë§Œ ì‹¤ì œ APIì—ì„œ ê¸°ì‚¬ ë¶ˆëŸ¬ì˜¤ê¸°(fetch_news_api).
    - ì´í›„ì—ëŠ” ë™ì¼ ê°ì²´(articles, retriever) ë°˜í™˜.
    """
    articles = fetch_news_api()  # 1ì£¼ì¼ì¹˜ ë‰´ìŠ¤ ê¸°ì‚¬ ë¶ˆëŸ¬ì˜¤ê¸°
    retriever = create_retriever_from_articles(articles)  # ë¬¸ì„œí™” + ë²¡í„° DB ìƒì„±
    return articles, retriever


##################################################
# (3) Streamlit ë©”ì¸
##################################################
def main():
    st.set_page_config(page_title="ë¯¸êµ­ ì¦ì‹œ ë‰´ìŠ¤ ì±—ë´‡", layout="wide")
    
    # ì œëª© ì„¤ì •
    st.title("ë¯¸êµ­ ì¦ì‹œ ë‰´ìŠ¤ ì±—ë´‡")
    
    # ì‹œì‘ì¼ê³¼ ëë‚˜ëŠ” ë‚ ì§œ ê³„ì‚°
    end_date_dt = datetime.now() - timedelta(days=1)
    start_date_dt = datetime.now() - timedelta(days=7)
    start_date_str = start_date_dt.strftime("%Yë…„ %mì›” %dì¼")
    end_date_str = end_date_dt.strftime("%Yë…„ %mì›” %dì¼")
    
    # ì„œë¸Œíƒ€ì´í‹€ ì¶”ê°€ (ì›ƒëŠ” ì´ëª¨í‹°ì½˜ í¬í•¨)
    st.markdown(f"ğŸ˜Š **{start_date_str} ~ {end_date_str}ê¹Œì§€ì˜ ë‰´ìŠ¤ë¥¼ í†µí•´ ì¦ì‹œë¥¼ ì•Œë ¤ë“œë ¤ìš”!**")
    
    # ë§¤ì¼ 00:01(=12ì‹œ1ë¶„)ì— cacheë¥¼ ë¹„ìš°ê³ , ìƒˆë¡œ ì¸ë±ì‹±í•˜ë„ë¡
    refresh_cache_if_1201()

    # (A) ìºì‹œì— ì €ì¥ëœ(ë˜ëŠ” ìƒˆë¡œ ìƒì„±ëœ) articles, retriever ê°€ì ¸ì˜¤ê¸°
    if "articles" not in st.session_state or "retriever" not in st.session_state:
        # ì²˜ìŒ(ì„œë²„ êµ¬ë™ í›„ ìµœì´ˆ ì ‘ê·¼)ì¸ ê²½ìš°ë‚˜, ì„¸ì…˜ì—ì„œ ì•„ì§ ì•ˆ ë¶ˆëŸ¬ì˜¨ ê²½ìš°
        articles, retriever = get_cached_articles_and_retriever()
        st.session_state["articles"] = articles
        st.session_state["retriever"] = retriever

    articles = st.session_state["articles"]
    retriever = st.session_state["retriever"]

    # ------------------- ì¹´ë“œë·° (í† ê¸€) -------------------
    with st.expander("ë¶ˆëŸ¬ì˜¨ ë‰´ìŠ¤ ëª©ë¡ (í¼ì¹˜ê¸°/ì ‘ê¸°)", expanded=False):
        st.write(f"ë¶ˆëŸ¬ì˜¨ ê¸°ì‚¬ ìˆ˜: {len(articles)}ê°œ")

        scroll_css = """
        <style>
        .horizontal-scroll {
            display: flex;
            flex-direction: row;
            align-items: center;
            height: 50px;
            overflow-x: auto;
            white-space: nowrap;
            border: 1px solid #ccc;
            border-radius: 6px;
            background-color: #fafafa;
            padding: 5px;
        }
        .news-card {
            display: inline-flex;
            align-items: center;
            height: 40px;
            padding: 0 10px;
            margin-right: 10px;
            text-decoration: none;
            color: inherit;
            border-right: 1px solid #ddd;
        }
        .news-card:last-child {
            border-right: none;
            margin-right: 0;
        }
        .news-card:hover {
            background-color: #eaeaea;
        }
        .title {
            font-weight: bold;
            margin-right: 5px;
        }
        .date {
            color: #666;
            font-size: 0.9rem;
        }
        </style>
        """
        st.markdown(scroll_css, unsafe_allow_html=True)

        st.markdown('<div class="horizontal-scroll">', unsafe_allow_html=True)
        for art in articles:
            url = art.get("content_url", "#")
            title_en = art.get("title", "ì œëª© ì—†ìŒ")
            title_ko = art.get("title_ko", "")
            if title_ko.strip():
                display_title = title_ko
            else:
                display_title = title_en

            date_ = art.get("published_at", "ë‚ ì§œ ì—†ìŒ")

            card_html = f"""
            <a class="news-card" href="{url}" target="_blank">
                <span class="title">{display_title}</span>
                <span class="date">({date_})</span>
            </a>
            """
            st.markdown(card_html, unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

    # ------------------- streamlit-chat -------------------

    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", "")

    # Send ë²„íŠ¼: ë¡œë”©ì¤‘ì´ë©´ disabled=True
    send_btn = st.button("Send", disabled=st.session_state.get("loading", False))

    if send_btn and user_input.strip():
        st.session_state["loading"] = True

        # (A) ì‚¬ìš©ì ë©”ì‹œì§€
        st.session_state["messages"].append({
            "role": "user",
            "content": user_input
        })

        # (B) ìµœê·¼ ëŒ€í™” 500ì
        entire_chat_text = "".join(m["content"] for m in st.session_state["messages"])
        last_500_chars = entire_chat_text[-500:]

        # (C) ê²€ìƒ‰
        if retriever:
            context_docs = retriever.get_relevant_documents(user_input)
            context_text = "\n".join([doc.page_content for doc in context_docs])

            # (D) RAG
            chain_input = {
                "context": context_text,
                "question": user_input,
                "chat_history": last_500_chars,
            }
            answer = rag_chain.invoke(chain_input)
        else:
            answer = "ì¸ë±ì‹±ëœ ê¸°ì‚¬ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

        # (E) ë´‡ ë©”ì‹œì§€
        st.session_state["messages"].append({
            "role": "assistant",
            "content": answer
        })

        st.session_state["loading"] = False

    # ë©”ì‹œì§€ í‘œì‹œ
    for i, msg in enumerate(st.session_state["messages"]):
        if msg["role"] == "user":
            message(msg["content"], is_user=True, key=f"user_{i}")
        else:
            message(msg["content"], is_user=False, key=f"assistant_{i}")


if __name__ == "__main__":
    main()
